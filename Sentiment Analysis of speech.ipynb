{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "import pyttsx3  \n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "import nltk \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.tokenize import PunktSentenceTokenizer \n",
    "from nltk.corpus import webtext \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer  \n",
    "speech = sr.Recognizer()  \n",
    "  \n",
    "# Function to convert text to speech \n",
    "\n",
    "def SpeakText(command): \n",
    "# Initialize the engine \n",
    "    \n",
    "    engine = pyttsx3.init() \n",
    "    engine.say(command)  \n",
    "    engine.runAndWait() \n",
    "\n",
    "#creating a list to store my speech as texts  \n",
    "MyText=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n",
      " Did you say :\n",
      "Hello my name is nehal i am studying in trinity college dublin i love machine learning and i want to be a machine learning engineer and i want to work in the field of data science thank you\n",
      "Ready!\n",
      " Did you say :\n",
      "Exit\n"
     ]
    }
   ],
   "source": [
    "# infinite loop for getting the speech\n",
    "while True:     \n",
    "      \n",
    "    # Exception handling to handle \n",
    "    # exceptions at the runtime \n",
    "    try: \n",
    "          \n",
    "        # use the microphone as source for input. \n",
    "        with sr.Microphone() as source:\n",
    "            \n",
    "            # wait for a second to let the recognizer \n",
    "            # adjust the energy threshold based on \n",
    "            # the surrounding noise level  \n",
    "            speech.adjust_for_ambient_noise(source, duration=0.1) \n",
    "            print(\"Ready!\")\n",
    "            SpeakText(\"Hey I am listening: \")\n",
    "           \n",
    "            #listens for the user's input  \n",
    "            audio2 = speech.listen(source) \n",
    "              \n",
    "            # Using google to recognize audio \n",
    "            #appending them to my list and captalising the first letter\n",
    "            MyText.append((speech.recognize_google(audio2)).capitalize()) \n",
    "           \n",
    "            print(\" Did you say :\")\n",
    "            print(MyText[-1]) \n",
    "            # reading out the text\n",
    "            SpeakText(MyText[-1])\n",
    "            # Ending the process when one say's exit\n",
    "            if MyText[-1] == 'Exit':\n",
    "                 break\n",
    "              \n",
    "    except sr.RequestError as e: \n",
    "        print(\"Could not request results; {0}\".format(e)) \n",
    "          \n",
    "    except sr.UnknownValueError: \n",
    "        print(\"unknown error occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello my name is nehal i am studying in trinity college dublin i love machine learning and i want to be a machine learning engineer and i want to work in the field of data science thank you']\n"
     ]
    }
   ],
   "source": [
    "# removing the 'exit' from the list\n",
    "MyText.pop()\n",
    "print(MyText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the list of strings to a single string\n",
    "def build_string(a):\n",
    "    string1 =\" \"\n",
    "    for i in a:\n",
    "         string1= string1 + \" \" + i\n",
    "    return string1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = build_string(MyText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translating the language to the deired language\n",
    "trans = Translator() \n",
    "#Check if the input language is English\n",
    "srcLang = trans.detect(string)\n",
    "if (srcLang.lang != 'en'):\n",
    "    #appending my speech to the list\n",
    "    trans = trans.translate(string, dest=lang)\n",
    "    translated = str(trans.text)\n",
    "else : translated = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'my', 'name', 'is', 'nehal', 'i', 'am', 'studying', 'in', 'trinity', 'college', 'dublin', 'i', 'love', 'machine', 'learning', 'and', 'i', 'want', 'to', 'be', 'a', 'machine', 'learning', 'engineer', 'and', 'i', 'want', 'to', 'work', 'in', 'the', 'field', 'of', 'data', 'science', 'thank', 'you']\n",
      "['Hello', 'name', 'nehal', 'studying', 'trinity', 'college', 'dublin', 'love', 'machine', 'learning', 'want', 'machine', 'learning', 'engineer', 'want', 'work', 'field', 'data', 'science', 'thank']\n"
     ]
    }
   ],
   "source": [
    "# removing the stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "word_tokens = word_tokenize(translated) \n",
    "  \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "  \n",
    "print(word_tokens) \n",
    "print(filtered_sentence) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Hello name nehal studying trinity college dublin love machine learning want machine learning engineer want work field data science thank'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = build_string(filtered_sentence)\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not using stemming as lemmatizing works better as it keeps the meaning of the word\n",
    "#words = word_tokenize(filtered_sentence) \n",
    "#ps = PorterStemmer()   \n",
    "#stemmed_sentence = [] \n",
    "#for w in words: \n",
    "     #stemmed_sentence.append(ps.stem(w)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  hello name nehal studi triniti colleg dublin love machin learn want machin learn engin want work field data scienc thank'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtered_sentence = build_string(stemmed_sentence)\n",
    "#filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizing as it keeps the meaning of the word\n",
    "words = word_tokenize(filtered_sentence)\n",
    "wl = WordNetLemmatizer()\n",
    "lemmatized_sentence = []\n",
    "for w in words: \n",
    "     lemmatized_sentence.append(wl.lemmatize(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  hello name nehal studi triniti colleg dublin love machin learn want machin learn engin want work field data scienc thank'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating string out of the tokenized words\n",
    "filtered_sentence = build_string(stemmed_sentence)\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the vadder sentiment analyser\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function for analysing\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hello name nehal studi triniti colleg dublin love machin learn want machin learn engin want work field data scienc thank {'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'compound': 0.8074}\n"
     ]
    }
   ],
   "source": [
    "#getting the score of the analyser\n",
    "sentiment_analyzer_scores(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hello name nehal studi triniti colleg dublin love machin learn want machin learn engin want work field data scienc thank {'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'compound': 0.8074}\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_scores(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
